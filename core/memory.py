import os
import json
from datetime import datetime
from typing import List
from .schema import TaskContext, MessageRole

class MirrorMemory:
    """
    Mirror Layer: äººç±»å¯è¯»çš„ Markdown æ—¥å¿—è®°å½•å™¨ã€‚
    è´Ÿè´£å°†æ‰€æœ‰äº¤äº’è®°å½•åˆ°æœ¬åœ°æ–‡ä»¶ä¸­ï¼Œä»¥ä¾¿å®¡è®¡å’Œè®°å¿†è¿½æº¯ã€‚
    """
    def __init__(self, log_dir: str = "logs/mirror"):
        self.log_dir = log_dir
        os.makedirs(log_dir, exist_ok=True)
        self.current_session_file = os.path.join(
            log_dir, 
            f"session_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md"
        )
        self._initialize_log()

    def _initialize_log(self):
        if not os.path.exists(self.current_session_file):
            with open(self.current_session_file, "w", encoding="utf-8") as f:
                f.write(f"# JANUS Mirror Log - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
                f.write("---")

    def log_task(self, context: TaskContext):
        """
        Record the completion of a task.
        """
        with open(self.current_session_file, "a", encoding="utf-8") as f:
            f.write(f"\n\n## ä»»åŠ¡: {context.task_id}\n")
            f.write(f"- **æ—¶é—´**: {datetime.now().strftime('%H:%M:%S')}\n")
            f.write(f"- **çŠ¶æ€**: {context.status.value}\n")
            
            f.write("\n### å¯¹è¯æµ:\n")
            for msg in context.messages:
                role_icon = "ğŸ‘¤" if msg.role == MessageRole.USER else "ğŸ¤–" if msg.role == MessageRole.ASSISTANT else "ğŸ›¡ï¸"
                f.write(f"**{role_icon} {msg.role.value.upper()}**:\n{msg.content}\n\n")
                
            if context.metadata.get("audit_report"):
                report = context.metadata["audit_report"]
                f.write(f"\n> **å®‰å…¨å®¡è®¡æŠ¥å‘Š**: {report['status']} - {report['rationale']}\n")
            
            f.write("\n---\n")
            
            # ç‰©ç†è½ç›˜ä¿éšœ (Physical Disk Persistence)
            f.flush()
            os.fsync(f.fileno())
            print(f"[è®°å¿†å±‚] ä»»åŠ¡ {context.task_id[:8]} å·²ç‰©ç†å›ºåŒ–è‡³é•œåƒæ—¥å¿—ã€‚")

    def list_logs(self) -> List[str]:
        """åˆ—å‡ºæ‰€æœ‰æ—¥å¿—æ–‡ä»¶ (List all log files)"""
        import glob
        logs = glob.glob(os.path.join(self.log_dir, "*.md"))
        return sorted([os.path.basename(l) for l in logs], reverse=True)

    def read_log(self, log_filename: str) -> str:
        """è¯»å–æŒ‡å®šæ—¥å¿—å†…å®¹ (Read specific log content)"""
        path = os.path.join(self.log_dir, log_filename)
        if not os.path.exists(path):
            return "æ—¥å¿—æ–‡ä»¶ä¸å­˜åœ¨ã€‚"
        with open(path, "r", encoding="utf-8") as f:
            return f.read()

# --- [AI-SAFEGUARD]: L4 è®°å¿†åˆ†å±‚ä½“ç³»é”å®š (DNA.md #2) ---
class KnowledgeStore:
    """
    Shadow Layer: å½±å­çŸ¥è¯†å±‚ã€‚
    è´Ÿè´£å­˜å‚¨ä»åˆ†æä¸­æå–çš„ç»“æ„åŒ–äº‹å® (Facts)ã€‚
    """
    def __init__(self, filename: str = "logs/knowledge.json"):
        self.filename = filename
        os.makedirs(os.path.dirname(filename), exist_ok=True)
        self.data = self._load()

    def _load(self) -> dict:
        if os.path.exists(self.filename):
            with open(self.filename, "r", encoding="utf-8") as f:
                data = json.load(f)
                # --- [AI-SAFEGUARD]: æ•°æ®åˆ†å±‚é€»è¾‘é”å®š (DNA.md #2) ---
                # ä¸¥ç¦å°† L1-L4 å±‚çº§åˆå¹¶ã€‚è¿™ç§ç‰©ç†éš”ç¦»ä¿éšœäº†è®°å¿†çš„è’¸é¦è·¯å¾„ã€‚
                if "facts" in data:
                    print(f"[çŸ¥è¯†å±‚] è¯†åˆ«åˆ°æ—§ç‰ˆæ‰å¹³ç»“æ„ï¼Œæ­£åœ¨æ‰§è¡Œç‰©ç†åˆ†å±‚è¿ç§»...")
                    new_struct = {
                        "episodic": [],   # L1/L2: æƒ…å¢ƒè®°å¿† (çŸ­æ—¶)
                        "conceptual": [], # L3: æ¦‚å¿µè®°å¿† (æ¶æ„, è§„åˆ™)
                        "semantic": [],   # L4: è¯­ä¹‰è®°å¿† (æ°¸æ’äº‹å®)
                        "preference": [], # L5: åå¥½è®°å¿† (ç”¨æˆ·ä¹ æƒ¯)
                        "last_updated": data.get("last_updated")
                    }
                    for fact in data["facts"]:
                        cat = fact.get("category", "")
                        # å¯å‘å¼è¿ç§»é€»è¾‘
                        if "Preference" in cat: layer = "preference"
                        elif "Perception" in cat: layer = "episodic"
                        elif cat in ["SystemRoadmap", "Infrastructure", "Evolution"]: layer = "conceptual"
                        else: layer = "semantic"
                        new_struct[layer].append(fact)
                    return new_struct
                
                # ç¡®ä¿å…¨å±‚çº§å­˜åœ¨ (Immutability Check)
                for k in ["episodic", "conceptual", "semantic", "preference"]:
                    if k not in data: data[k] = []
                return data
        
        return {
            "episodic": [], 
            "conceptual": [], 
            "semantic": [], 
            "preference": [],
            "last_updated": None
        }

    def _save(self):
        self.data["last_updated"] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        with open(self.filename, "w", encoding="utf-8") as f:
            json.dump(self.data, f, ensure_ascii=False, indent=2)
            f.flush()
            os.fsync(f.fileno())
            # print(f"[çŸ¥è¯†å±‚] å½±å­äº‹å®å·²åŒæ­¥è‡³æŒä¹…åŒ–å­˜å‚¨ã€‚")

    def add_fact(self, category: str, content: str, source_task: str, layer: str = "episodic"):
        """
        è®°å½•ä¸€ä¸ªæ–°äº‹å®ã€‚
        layer: [episodic, conceptual, semantic, preference]
        """
        if layer not in self.data:
            layer = "episodic"

        # 1. ç®€å•é‡æ„å»é‡ (Deduplication)
        # æ£€æŸ¥è¯¥å±‚æœ€å 50 æ¡äº‹å®
        for fact in self.data[layer][-50:]:
            if fact["category"] == category and fact["content"] == content:
                try:
                    last_time = datetime.strptime(fact["timestamp"], '%Y-%m-%d %H:%M:%S')
                    # å¯¹ç›¸åŒå†…å®¹çš„äº‹å®ï¼Œ300ç§’å†…ä¸é‡å¤è®°å½•ï¼ˆé™¤éæ˜¯å…³é”®çŠ¶æ€å˜æ›´ï¼‰
                    if (datetime.now() - last_time).total_seconds() < 300:
                        return
                except:
                    return

        # 2. æ’å…¥æ–°äº‹å® (Insertion)
        self.data[layer].append({
            "category": category,
            "content": content,
            "source": source_task,
            "timestamp": datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        })
        self._save()
        # 3. è‡ªåŠ¨ç»´æŠ¤ (Auto-Maintenance)
        self.prune_facts()

    def query_facts(self, keyword: str, layer: str = None) -> List[dict]:
        """
        è·¨å±‚çº§äº‹å®æŸ¥è¯¢ã€‚
        """
        results = []
        keywords = keyword.lower().split()
        
        # ç¡®å®šæœç´¢èŒƒå›´
        target_layers = [layer] if layer and layer in self.data else ["preference", "semantic", "conceptual", "episodic"]
        
        for lyr in target_layers:
            if lyr == "last_updated": continue
            for fact in self.data[lyr]:
                fact_str = f"{fact['category']} {fact['content']}".lower()
                if all(k in fact_str for k in keywords):
                    # æ³¨å…¥å±‚çº§ä¿¡æ¯ä¾›å‰ç«¯å±•ç¤º
                    fact_with_layer = fact.copy()
                    fact_with_layer["_layer"] = lyr
                    results.append(fact_with_layer)
                
        return results

    def prune_facts(self):
        """
        [AI-SAFEGUARD]: é—å¿˜ä¸ä¿®å‰ªç®—æ³•é”å®šã€‚
        - Episodic: æ—¶é—´ä»£è°¢ (24h)
        - Conceptual/Semantic: å®¹é‡ç®¡ç†
        ç¦æ­¢å°†ä¿®å‰ªé€»è¾‘é€šç”¨åŒ–ï¼Œä¸åŒå±‚çº§çš„ç”Ÿå‘½å‘¨æœŸæˆªç„¶ä¸åŒã€‚
        """
        # 1. æƒ…å¢ƒå†³ç­–ï¼šä»£è°¢è¶…è¿‡ 24 å°æ—¶çš„è®°å½• (Episodic Pruning)
        cutoff = 86400 # 24 å°æ—¶
        now = datetime.now()
        
        original_len = len(self.data["episodic"])
        self.data["episodic"] = [
            f for f in self.data["episodic"]
            if (now - datetime.strptime(f["timestamp"], '%Y-%m-%d %H:%M:%S')).total_seconds() < cutoff
        ]
        
        # 2. å®¹é‡é™åˆ¶ (Capacity Pruning)
        for lyr in ["conceptual", "semantic", "preference"]:
            max_size = 500 if lyr == "conceptual" else 200
            if len(self.data[lyr]) > max_size:
                self.data[lyr] = self.data[lyr][-max_size:]

        if len(self.data["episodic"]) != original_len:
            self._save()

